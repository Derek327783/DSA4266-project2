# DSA4266-project2

## Clone the repository 
`git clone https://github.com/Derek327783/DSA4266-project2.git`
## Files required for prediction

1. `best.h5` model file
2. dataset file with `.json` extension
3. `detect_json.py` file
4. `pipeline.sh` file

**Ensure all the files are within the same directory.**

**Do not change the file name for `best.h5` and `detect_json.py` as `pipeline.sh` will check for the presence of those files.**

## Options for configuration

- [Pipeline configuration and prediction execution](#pipeline-configuration-and-prediction-execution)
- [Manual Configuration](#manual-configuration)

### Pipeline configuration and prediction execution

1. Ensure the dataset, `best.h5` file, `pipeline.sh` and `detect_json.py` are within the same directory.

2. To allow the `pipeline.sh` file to be executable, type `chmod +x pipeline.sh`.

3. Type the following to start the prediction for a specific dataset.
```
./pipeline.sh predict <dataset file>
```
**ensure that dataset is of `.json` format.**

#### Remove all files generated by prediction

- Type the following:
```
./pipeline.sh clean
```
Note that this will only remove files generated by `detect_json.py` found within the local `output` directory. Any modifications to the file name or directory will cause the file to not be removed. The local `output` directory will be created upon running `pipeline.sh`.

### Manual configuration

- [Virtual_environment](#virtual_environment)
- [Training](#training)
- [Prediction](#prediction)

#### Virtual_environment

1. Install python3 virtual environment
```bash
sudo apt install python3.8-venv
```

2. Create and activate virtual environment
```bash
python3 -m venv venv
source ./venv/bin/activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```


#### Training

```console
> python train.py 
usage: train.py [--epochs E] [--batch_size B] [--data D] [--test_data T]
                
Train the model

optional arguments:
  --epochs E      Number of epochs default is 32
  --batch-size B  Batch size default is 200
  --data D        Training data directiory in json format default is ./data/train_OG.csv
  --test_data T   Test data directory in json format default is ./data/test_OG.csv
```


#### Prediction
```console
> python detect_json.py 
usage: detect_json.py [--model M] [--data D]
                
Train the model

optional arguments:
  --model M     model directory in h5 format
  --data  D     data directory in json format
```
